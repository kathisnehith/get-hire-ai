{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37541b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import time\n",
    "import json\n",
    "import tiktoken\n",
    "from PyPDF2 import PdfReader\n",
    "import streamlit as st\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d425d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.environ[\"GITHUB_API_TOKEN\"]\n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "client = OpenAI(base_url=endpoint,\n",
    "    api_key=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22280c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32956aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text, encoding_name=\"o200k_base\"):\n",
    "    enc = tiktoken.get_encoding(encoding_name)\n",
    "    return len(enc.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a16d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call_openai(model_name, messages, max_tokens, output_format):\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=0.9,\n",
    "        model=model_name,\n",
    "        response_format=output_format\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d647d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class structured_output(BaseModel):\n",
    "    skills: list[str]\n",
    "    resume_init_suggestions: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STREAMLIT APP - {input, output, and processing}\n",
    "\n",
    "\n",
    "#st.set_page_config(page_title=\"Resume Analyzer\", page_icon=\":mag_right:\")\n",
    "#st.title(\"Resume Analyzer\")\n",
    "#resume_file = st.file_uploader(\"Upload your resume (PDF format)\", type=[\"pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b31bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text= extract_text_from_pdf(r\"/Users/kathisnehith/Downloads/Shivananda_Dayananda_Resume (2).pdf\")\n",
    "user_prompt= f\"Analyze the resume get the suggestions and top skills. \\n\\n{resume_text}\"\n",
    "system_instruction = \"\"\" You are a resume analysis expert. When given a resume document, analyze it to provide:\n",
    "\n",
    "1. **Suggestive Changes**: 3-4 specific, actionable improvements to enhance the resume's impact. Focus on:\n",
    "   - Quantifying achievements with metrics/numbers\n",
    "   - Using Harvard-style action verbs and result-oriented language\n",
    "   - Improving structure, formatting, or section organization\n",
    "   - Strengthening weak bullet points with specific accomplishments\n",
    "   - Adding missing technical keywords relevant to their field\n",
    "\n",
    "2. **Top 5 Skills**: The most relevant technical and professional skills based on frequency, recency, and industry importance.\n",
    "\n",
    "For each job in work experience, identify:\n",
    "- Job title, company, and duration\n",
    "- Key technologies and skills used\n",
    "- Quantifiable achievements and impact\n",
    "\n",
    "Output format: (in given structured format requested)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ce723ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"resume_init_suggestions\":[\"Quantify achievements more consistently by including specific metrics for all bullet points, such as the percentage of improvement or cost savings for each project.\",\"Use stronger action verbs at the beginning of each bullet point. For example, replace 'Engineered' with 'Architected' or 'Deployed' with 'Implemented' to convey a stronger sense of leadership and responsibility.\",\"Improve the structure of the Skills section by categorizing skills into sub-sections (e.g., Programming Languages, Cloud Technologies, Databases) for better readability.\",\"Add a 'Technical Keywords' section that highlights industry-relevant terms, such as 'Data Warehousing', 'ETL', 'Machine Learning', or 'Big Data', to enhance visibility in applicant tracking systems.\"],\"skills\":[\"AWS (EC2, S3, Redshift)\",\"Data Engineering (ETL, Data Pipelines)\",\"SQL & NoSQL Databases (PostgreSQL, MongoDB)\",\"Python & Spark Programming\",\"Data Visualization (Grafana, Power BI)\"]}\n",
      "['AWS (EC2, S3, Redshift)', 'Data Engineering (ETL, Data Pipelines)', 'SQL & NoSQL Databases (PostgreSQL, MongoDB)', 'Python & Spark Programming', 'Data Visualization (Grafana, Power BI)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"openai/gpt-4o-mini\"\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_instruction},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "\n",
    "skills_extract = llm_call_openai(model_name, messages, 350, structured_output)\n",
    "print(skills_extract)\n",
    "s=json.loads(skills_extract)\n",
    "\n",
    "print(s['skills'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store slider values in session_state for later use\n",
    "for skill in s[\"skills\"]:\n",
    "    slider_key = f\"skill_{skill}\"\n",
    "    st.session_state[slider_key] = st.slider(skill, min_value=0, max_value=10, value=1, key=slider_key)\n",
    "\n",
    "# Example: Store user input as well\n",
    "user_notes = st.text_area(\"Add your notes or context\")\n",
    "st.session_state[\"user_notes\"] = user_notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_call_openai(model_name, messages, 350, structured_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
